name: PR Review

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.issue.number || github.event.inputs.prNumber }}
  cancel-in-progress: false

on:
  pull_request_target:
    types: [opened, synchronize, ready_for_review]
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      prNumber:
        description: 'The number of the PR to review manually'
        required: true
        type: string

jobs:
  review-pr:
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.action == 'opened' && github.event.pull_request.draft == false) ||
      github.event.action == 'ready_for_review' ||
      (github.event.action == 'synchronize' && contains(github.event.pull_request.labels.*.name, 'Agent Monitored')) ||
      (
        github.event_name == 'issue_comment' &&
        github.event.issue.pull_request &&
        (contains(github.event.comment.body, '/mirrobot-review') || contains(github.event.comment.body, '/mirrobot_review'))
      )
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    env:
      PR_NUMBER: ${{ github.event.pull_request.number || github.event.issue.number || inputs.prNumber }}
      BOT_NAMES_JSON: '["mirrobot", "mirrobot-agent", "mirrobot-agent[bot]"]'
      IGNORE_BOT_NAMES_JSON: '["ellipsis-dev"]'
      COMMENT_FETCH_LIMIT: '40'
      REVIEW_FETCH_LIMIT: '20'
      REVIEW_THREAD_FETCH_LIMIT: '25'
      THREAD_COMMENT_FETCH_LIMIT: '10'

    steps:

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Bot Setup
        id: setup
        uses: ./.github/actions/bot-setup
        with:
          bot-app-id: ${{ secrets.BOT_APP_ID }}
          bot-private-key: ${{ secrets.BOT_PRIVATE_KEY }}
          opencode-api-key: ${{ secrets.OPENCODE_API_KEY }}
          opencode-model: ${{ secrets.OPENCODE_MODEL }}
          opencode-fast-model: ${{ secrets.OPENCODE_FAST_MODEL }}
          custom-providers-json: ${{ secrets.CUSTOM_PROVIDERS_JSON }}

      - name: Add reaction to PR
        env:
          GH_TOKEN: ${{ steps.setup.outputs.token }}
          BOT_NAMES_JSON: ${{ env.BOT_NAMES_JSON }}
          IGNORE_BOT_NAMES_JSON: ${{ env.IGNORE_BOT_NAMES_JSON }}
        run: |
          gh api \
            --method POST \
            -H "Accept: application/vnd.github+json" \
            /repos/${{ github.repository }}/issues/${{ env.PR_NUMBER }}/reactions \
            -f content='eyes'

      - name: Fetch and Format Full PR Context
        id: pr_meta
        env:
          GH_TOKEN: ${{ steps.setup.outputs.token }}
        run: |
          # Fetch core PR metadata (comments and reviews fetched via GraphQL below)
          pr_json=$(gh pr view ${{ env.PR_NUMBER }} --repo ${{ github.repository }} --json author,title,body,createdAt,state,headRefName,baseRefName,headRefOid,additions,deletions,commits,files,closingIssuesReferences,headRepository)
          # Fetch timeline data to find cross-references
          timeline_data=$(gh api "/repos/${{ github.repository }}/issues/${{ env.PR_NUMBER }}/timeline")

          repo_owner="${GITHUB_REPOSITORY%/*}"
          repo_name="${GITHUB_REPOSITORY#*/}"
          GRAPHQL_QUERY='query($owner:String!, $name:String!, $number:Int!, $commentLimit:Int!, $reviewLimit:Int!, $threadLimit:Int!, $threadCommentLimit:Int!) {
            repository(owner: $owner, name: $name) {
              pullRequest(number: $number) {
                comments(last: $commentLimit) {
                  nodes {
                    databaseId
                    author { login }
                    body
                    createdAt
                    isMinimized
                    minimizedReason
                  }
                }
                reviews(last: $reviewLimit) {
                  nodes {
                    databaseId
                    author { login }
                    body
                    state
                    submittedAt
                  }
                }
                reviewThreads(last: $threadLimit) {
                  nodes {
                    id
                    isResolved
                    isOutdated
                    comments(last: $threadCommentLimit) {
                      nodes {
                        databaseId
                        author { login }
                        body
                        createdAt
                        path
                        line
                        originalLine
                        diffHunk
                        isMinimized
                        minimizedReason
                        pullRequestReview {
                          databaseId
                          isMinimized
                          minimizedReason
                        }
                      }
                    }
                  }
                }
              }
            }
          }'

          discussion_data=$(gh api graphql \
            -F owner="$repo_owner" \
            -F name="$repo_name" \
            -F number=${{ env.PR_NUMBER }} \
            -F commentLimit=${{ env.COMMENT_FETCH_LIMIT }} \
            -F reviewLimit=${{ env.REVIEW_FETCH_LIMIT }} \
            -F threadLimit=${{ env.REVIEW_THREAD_FETCH_LIMIT }} \
            -F threadCommentLimit=${{ env.THREAD_COMMENT_FETCH_LIMIT }} \
            -f query="$GRAPHQL_QUERY")

          # Debug: Output pr_json and the discussion GraphQL payload for inspection
          echo "$pr_json" > pr_json.txt
          echo "$discussion_data" > discussion_data.txt
          
          # For checkout step
          repo_full_name=$(echo "$pr_json" | jq -r '.headRepository.nameWithOwner // "${{ github.repository }}"')
          echo "repo_full_name=$repo_full_name" >> $GITHUB_OUTPUT
          echo "ref_name=$(echo "$pr_json" | jq -r .headRefName)" >> $GITHUB_OUTPUT

          # Prepare metadata
          author=$(echo "$pr_json" | jq -r .author.login)
          created_at=$(echo "$pr_json" | jq -r .createdAt)
          base_branch=$(echo "$pr_json" | jq -r .baseRefName)
          head_branch=$(echo "$pr_json" | jq -r .headRefName)
          state=$(echo "$pr_json" | jq -r .state)
          additions=$(echo "$pr_json" | jq -r .additions)
          deletions=$(echo "$pr_json" | jq -r .deletions)
          total_commits=$(echo "$pr_json" | jq -r '.commits | length')
          changed_files_count=$(echo "$pr_json" | jq -r '.files | length')
          title=$(echo "$pr_json" | jq -r .title)
          body=$(echo "$pr_json" | jq -r '.body // "(No description provided)"')
          # Build changed files list with correct jq interpolations for additions and deletions
          # Previous pattern had a missing backslash before the deletions interpolation, leaving a literal '((.deletions))'.
          changed_files_list=$(echo "$pr_json" | jq -r '.files[] | "- \(.path) (MODIFIED) +\((.additions))/-\((.deletions))"')
          comments=$(echo "$discussion_data" | jq -r --argjson ignored "$IGNORE_BOT_NAMES_JSON" '
            ((.data.repository.pullRequest.comments.nodes // [])
              | map(select((.isMinimized != true) and (((.author.login? // "unknown") as $login | $ignored | index($login)) | not))))
            | if length > 0 then
                map("- " + (.author.login? // "unknown") + " at " + (.createdAt // "N/A") + ":\n" + ((.body // "") | tostring) + "\n")
                | join("")
              else
                "No general comments."
              end')
          
          # ===== ENHANCED FILTERING WITH ERROR HANDLING =====
          
          # Count totals before filtering
          total_reviews=$(echo "$discussion_data" | jq --argjson ignored "$IGNORE_BOT_NAMES_JSON" '[((.data.repository.pullRequest.reviews.nodes // [])[]? | select((.author.login? // "unknown") as $login | $ignored | index($login) | not))] | length')
            total_review_comments=$(echo "$discussion_data" | jq --argjson ignored "$IGNORE_BOT_NAMES_JSON" '((.data.repository.pullRequest.reviewThreads.nodes // [])
              | map(select(.isResolved != true and .isOutdated != true))
              | map(.comments.nodes // [])
              | flatten
              | map(select(((.author.login? // "unknown") as $login | $ignored | index($login)) | not))
              | length) // 0')
          echo "Debug: total reviews before filtering = $total_reviews"
          echo "Debug: total review comments before filtering = $total_review_comments"
          
          # Filter reviews: exclude COMMENTED (duplicates inline comments) and DISMISSED states
          # Fallback to unfiltered if jq fails
          review_filter_err=$(mktemp 2>/dev/null || echo "/tmp/review_filter_err.log")
          if reviews=$(echo "$discussion_data" | jq -r --argjson ignored "$IGNORE_BOT_NAMES_JSON" 'if ((((.data.repository.pullRequest.reviews.nodes // []) | length) > 0)) then ((.data.repository.pullRequest.reviews.nodes // [])[]? | select((.author.login? // "unknown") as $login | $ignored | index($login) | not and .body != null and .state != "COMMENTED" and .state != "DISMISSED") | "- " + (.author.login? // "unknown") + " at " + (.submittedAt // "N/A") + ":\n - Review body: " + (.body // "No summary comment.") + "\n - State: " + (.state // "UNKNOWN") + "\n") else "No formal reviews." end' 2>"$review_filter_err"); then
            filtered_reviews=$(echo "$reviews" | grep -c "^- " || true)
            filtered_reviews=${filtered_reviews//[^0-9]/}
            [ -z "$filtered_reviews" ] && filtered_reviews=0
            total_reviews=${total_reviews//[^0-9]/}
            [ -z "$total_reviews" ] && total_reviews=0
            excluded_reviews=$(( total_reviews - filtered_reviews )) || excluded_reviews=0
            echo "✓ Filtered reviews: $filtered_reviews included, $excluded_reviews excluded (COMMENTED/DISMISSED)"
            if [ -s "$review_filter_err" ]; then
              echo "::debug::jq stderr (reviews) emitted output:" 
              cat "$review_filter_err"
            fi
          else
            jq_status=$?
            echo "::warning::Review filtering failed (exit $jq_status), using unfiltered data"
            if [ -s "$review_filter_err" ]; then
              echo "::warning::jq stderr (reviews):"
              cat "$review_filter_err"
            else
              echo "::warning::jq returned no stderr for reviews filter"
            fi
            reviews=$(echo "$discussion_data" | jq -r --argjson ignored "$IGNORE_BOT_NAMES_JSON" 'if ((((.data.repository.pullRequest.reviews.nodes // []) | length) > 0)) then ((.data.repository.pullRequest.reviews.nodes // [])[]? | select((.author.login? // "unknown") as $login | $ignored | index($login) | not and .body != null) | "- " + (.author.login? // "unknown") + " at " + (.submittedAt // "N/A") + ":\n - Review body: " + (.body // "No summary comment.") + "\n - State: " + (.state // "UNKNOWN") + "\n") else "No formal reviews." end')
            excluded_reviews=0
            echo "FILTER_ERROR_REVIEWS=true" >> $GITHUB_ENV
          fi
          rm -f "$review_filter_err" || true
          
          # Filter review comments: exclude outdated comments
          # Fallback to unfiltered if jq fails
          review_comment_filter_err=$(mktemp 2>/dev/null || echo "/tmp/review_comment_filter_err.log")
          if review_comments=$(echo "$discussion_data" | jq -r --argjson ignored "$IGNORE_BOT_NAMES_JSON" '
            ((.data.repository.pullRequest.reviewThreads.nodes // [])
              | map(select(
                  .isResolved != true and .isOutdated != true
                  and (((.comments.nodes // []) | first | .isMinimized) != true)
                  and ((((.comments.nodes // []) | first | .pullRequestReview.isMinimized) // false) != true)
                ))
              | map(.comments.nodes // [])
              | flatten
              | map(select((.isMinimized != true)
                           and ((.pullRequestReview.isMinimized // false) != true)
                           and (((.author.login? // "unknown") as $login | $ignored | index($login)) | not))))
            | if length > 0 then
                map("- " + (.author.login? // "unknown") + " at " + (.createdAt // "N/A") + " (" + (.path // "Unknown file") + ":" + ((.line // .originalLine // "N/A") | tostring) + "):\n   " + ((.body // "") | tostring) + "\n")
                | join("")
              else
                "No inline review comments."
              end' 2>"$review_comment_filter_err"); then
            filtered_comments=$(echo "$review_comments" | grep -c "^- " || true)
            filtered_comments=${filtered_comments//[^0-9]/}
            [ -z "$filtered_comments" ] && filtered_comments=0
            total_review_comments=${total_review_comments//[^0-9]/}
            [ -z "$total_review_comments" ] && total_review_comments=0
            excluded_comments=$(( total_review_comments - filtered_comments )) || excluded_comments=0
            echo "✓ Filtered review comments: $filtered_comments included, $excluded_comments excluded (outdated)"
            if [ -s "$review_comment_filter_err" ]; then
              echo "::debug::jq stderr (review comments) emitted output:"
              cat "$review_comment_filter_err"
            fi
          else
            jq_status=$?
            echo "::warning::Review comment filtering failed (exit $jq_status), using unfiltered data"
            if [ -s "$review_comment_filter_err" ]; then
              echo "::warning::jq stderr (review comments):"
              cat "$review_comment_filter_err"
            else
              echo "::warning::jq returned no stderr for review comment filter"
            fi
            review_comments=$(echo "$discussion_data" | jq -r --argjson ignored "$IGNORE_BOT_NAMES_JSON" '
              ((.data.repository.pullRequest.reviewThreads.nodes // [])
                | map(select(
                    (((.comments.nodes // []) | first | .isMinimized) != true)
                    and ((((.comments.nodes // []) | first | .pullRequestReview.isMinimized) // false) != true)
                  ))
                | map(.comments.nodes // [])
                | flatten
                | map(select((.isMinimized != true)
                             and ((.pullRequestReview.isMinimized // false) != true)
                             and (((.author.login? // "unknown") as $login | $ignored | index($login)) | not))))
              | if length > 0 then
                  map("- " + (.author.login? // "unknown") + " at " + (.createdAt // "N/A") + " (" + (.path // "Unknown file") + ":" + ((.line // .originalLine // "N/A") | tostring) + "):\n   " + ((.body // "") | tostring) + "\n")
                  | join("")
                else
                  "No inline review comments."
                end')
            excluded_comments=0
            echo "FILTER_ERROR_COMMENTS=true" >> $GITHUB_ENV
          fi
          rm -f "$review_comment_filter_err" || true
          
          # Store filtering statistics
          echo "EXCLUDED_REVIEWS=$excluded_reviews" >> $GITHUB_ENV
          echo "EXCLUDED_COMMENTS=$excluded_comments" >> $GITHUB_ENV

          # Prepare linked issues robustly by fetching each one individually
          linked_issues_content=""
          issue_numbers=$(echo "$pr_json" | jq -r '.closingIssuesReferences[].number')
          if [ -z "$issue_numbers" ]; then
            linked_issues="No issues are formally linked for closure by this PR."
          else
            for number in $issue_numbers; do
              issue_details_json=$(gh issue view "$number" --repo "${{ github.repository }}" --json title,body 2>/dev/null || echo "{}")
              issue_title=$(echo "$issue_details_json" | jq -r '.title // "Title not available"')
              issue_body=$(echo "$issue_details_json" | jq -r '.body // "Body not available"')
              linked_issues_content+=$(printf "<issue>\n <number>#%s</number>\n <title>%s</title>\n <body>\n%s\n</body>\n</issue>\n" "$number" "$issue_title" "$issue_body")
            done
            linked_issues=$linked_issues_content
          fi

          # Prepare cross-references from timeline data
          references=$(echo "$timeline_data" | jq -r '.[] | select(.event == "cross-referenced") | .source.issue | "- Mentioned in \(.html_url | if contains("/pull/") then "PR" else "Issue" end): #\(.number) - \(.title)"')
          if [ -z "$references" ]; then references="This PR has not been mentioned in other issues or PRs."; fi

          # Build filtering summary for AI context
          # Ensure numeric fallbacks so blanks never appear if variables are empty
          filter_summary="Context filtering applied: ${excluded_reviews:-0} reviews and ${excluded_comments:-0} review comments excluded from this context."
          if [ "${FILTER_ERROR_REVIEWS}" = "true" ] || [ "${FILTER_ERROR_COMMENTS}" = "true" ]; then
            filter_summary="$filter_summary"$'\n'"Warning: Some filtering operations encountered errors. Context may include items that should have been filtered."
          fi

          # Assemble the final context block
          CONTEXT_DELIMITER="GH_PR_CONTEXT_DELIMITER_$(openssl rand -hex 8)"
          echo "PULL_REQUEST_CONTEXT<<$CONTEXT_DELIMITER" >> "$GITHUB_ENV"
          echo "Author: $author" >> "$GITHUB_ENV"
          echo "Created At: $created_at" >> "$GITHUB_ENV"
          echo "Base Branch (target): $base_branch" >> "$GITHUB_ENV"
          echo "Head Branch (source): $head_branch" >> "$GITHUB_ENV"
          echo "State: $state" >> "$GITHUB_ENV"
          echo "Additions: $additions" >> "$GITHUB_ENV"
          echo "Deletions: $deletions" >> "$GITHUB_ENV"
          echo "Total Commits: $total_commits" >> "$GITHUB_ENV"
          echo "Changed Files: $changed_files_count files" >> "$GITHUB_ENV"
          echo "<pull_request_body>" >> "$GITHUB_ENV"
          echo "$title" >> "$GITHUB_ENV"
          echo "---" >> "$GITHUB_ENV"
          echo "$body" >> "$GITHUB_ENV"
          echo "</pull_request_body>" >> "$GITHUB_ENV"
          echo "<pull_request_comments>" >> "$GITHUB_ENV"
          echo "$comments" >> "$GITHUB_ENV"
          echo "</pull_request_comments>" >> "$GITHUB_ENV"
          echo "<pull_request_reviews>" >> "$GITHUB_ENV"
          echo "$reviews" >> "$GITHUB_ENV"
          echo "</pull_request_reviews>" >> "$GITHUB_ENV"
          echo "<pull_request_review_comments>" >> "$GITHUB_ENV"
          echo "$review_comments" >> "$GITHUB_ENV"
          echo "</pull_request_review_comments>" >> "$GITHUB_ENV"
          echo "<pull_request_changed_files>" >> "$GITHUB_ENV"
          echo "$changed_files_list" >> "$GITHUB_ENV"
          echo "</pull_request_changed_files>" >> "$GITHUB_ENV"
          echo "<linked_issues>" >> "$GITHUB_ENV"
          echo "$linked_issues" >> "$GITHUB_ENV"
          echo "</linked_issues>" >> "$GITHUB_ENV"
          echo "<cross_references>" >> "$GITHUB_ENV"
          echo "$references" >> "$GITHUB_ENV"
          echo "</cross_references>" >> "$GITHUB_ENV"
          echo "<filtering_summary>" >> "$GITHUB_ENV"
          echo "$filter_summary" >> "$GITHUB_ENV"
          echo "</filtering_summary>" >> "$GITHUB_ENV"
          echo "$CONTEXT_DELIMITER" >> "$GITHUB_ENV"
          echo "PR_HEAD_SHA=$(echo "$pr_json" | jq -r .headRefOid)" >> $GITHUB_ENV
          echo "PR_AUTHOR=$author" >> $GITHUB_ENV
          echo "BASE_BRANCH=$base_branch" >> $GITHUB_ENV

      

      - name: Determine Review Type and Last Reviewed SHA
        id: review_type
        env:
          GH_TOKEN: ${{ steps.setup.outputs.token }}
          BOT_NAMES_JSON: ${{ env.BOT_NAMES_JSON }}
        run: |
          # Search for a previous summary comment from the bot using a distinctive footer.
          # This is more robust as it finds all review summaries, not just those with the SHA marker.
          # This now fetches both comments and reviews to find the last summary.
          # It checks for different author names and uses a more robust contains check.
          pr_summary_payload=$(gh pr view ${{ env.PR_NUMBER }} --repo ${{ github.repository }} --json comments,reviews)
          last_summary_comment=$(echo "$pr_summary_payload" | jq -r --argjson bots "$BOT_NAMES_JSON" '
            [
              (.comments[]? | {body: (.body // ""), timestamp: (.updatedAt // .createdAt // ""), author: (.author.login // "unknown")} ),
              (.reviews[]? | {body: (.body // ""), timestamp: (.submittedAt // .updatedAt // .createdAt // ""), author: (.author.login // "unknown")} )
            ]
            | map(select((.author as $login | $bots | index($login)) and ((.body | test("<!-- last_reviewed_sha:[a-f0-9]{7,40} -->")) or (.body | contains("This review was generated by an AI assistant.")))))
            | sort_by(.timestamp)
            | last
            | .body // ""
          ')

          if [ -z "$last_summary_comment" ]; then
            echo "This is the first review."
            echo "is_first_review=true" >> $GITHUB_OUTPUT
            echo "last_reviewed_sha=" >> $GITHUB_OUTPUT
            echo "" > last_summary_comment.txt
            echo "" > last_review_sha.txt
          else
            echo "Follow-up review detected. Previous summary found."
            echo "is_first_review=false" >> $GITHUB_OUTPUT
            echo "$last_summary_comment" > last_summary_comment.txt
            
            # Now, try to extract the SHA from this specific comment
            last_sha=$(echo "$last_summary_comment" | sed -n 's/.*<!-- last_reviewed_sha:\([a-f0-9]\{7,40\}\) -->.*/\1/p')
            
            if [ -n "$last_sha" ]; then
              echo "Found last reviewed SHA: $last_sha"
              echo "last_reviewed_sha=$last_sha" >> $GITHUB_OUTPUT
              echo "$last_sha" > last_review_sha.txt
            else
              # A summary exists, but no SHA was found. The AI will perform a full review.
              echo "Could not extract SHA from the last summary. The AI will perform a full review."
              echo "last_reviewed_sha=" >> $GITHUB_OUTPUT
              echo "" > last_review_sha.txt
            fi
          fi

      

      - name: Save secure prompt from base branch
        run: cp .github/prompts/pr-review.md /tmp/pr-review.md

      - name: Checkout PR head
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.pr_meta.outputs.repo_full_name }}
          ref: ${{ steps.pr_meta.outputs.ref_name }}
          token: ${{ steps.setup.outputs.token }}
          fetch-depth: 0  # Full history needed for diff generation

      - name: Generate PR Diff for First Review
        if: steps.review_type.outputs.is_first_review == 'true'
        id: first_review_diff
        run: |
          BASE_BRANCH="${{ env.BASE_BRANCH }}"
          CURRENT_SHA="${PR_HEAD_SHA}"
          DIFF_CONTENT=""
          # Ensure dedicated diff folder exists in the workspace (hidden to avoid accidental use)
          mkdir -p "$GITHUB_WORKSPACE/.mirrobot_files"
          
          echo "Generating full PR diff against base branch: $BASE_BRANCH"
          
          # Fetch the base branch to ensure we have it
          if git fetch origin "$BASE_BRANCH":refs/remotes/origin/"$BASE_BRANCH" 2>/dev/null; then
            echo "Successfully fetched base branch $BASE_BRANCH."
            
            # Find merge base (common ancestor)
            if MERGE_BASE=$(git merge-base origin/"$BASE_BRANCH" "$CURRENT_SHA" 2>/dev/null); then
              echo "Found merge base: $MERGE_BASE"
              
              # Generate diff from merge base to current commit
              if DIFF_CONTENT=$(git diff --patch "$MERGE_BASE".."$CURRENT_SHA" 2>/dev/null); then
                DIFF_SIZE=${#DIFF_CONTENT}
                DIFF_LINES=$(echo "$DIFF_CONTENT" | wc -l)
                echo "Generated PR diff: $DIFF_LINES lines, $DIFF_SIZE characters"
                
                # Truncate if too large (500KB limit to avoid context overflow)
                if [ $DIFF_SIZE -gt 500000 ]; then
                  echo "::warning::PR diff is very large ($DIFF_SIZE chars). Truncating to 500KB."
                  TRUNCATION_MSG=$'\n\n[DIFF TRUNCATED - PR is very large. Showing first 500KB only. Review scaled to high-impact areas.]'
                  DIFF_CONTENT="${DIFF_CONTENT:0:500000}${TRUNCATION_MSG}"
                fi
                # Write diff directly into the repository workspace in the dedicated folder
                echo "$DIFF_CONTENT" > "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
              else
                echo "::warning::Could not generate diff. Using changed files list only."
                DIFF_CONTENT="(Diff generation failed. Please refer to the changed files list above.)"
                # Write fallback diff directly into the workspace folder
                echo "$DIFF_CONTENT" > "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
              fi
            else
            echo "::warning::Could not find merge base between $BASE_BRANCH and $CURRENT_SHA."
            DIFF_CONTENT="(No common ancestor found. This might be a new branch or orphaned commits.)"
            # Write fallback diff content directly into the repository workspace folder
            echo "$DIFF_CONTENT" > "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
            fi
          else
            echo "::warning::Could not fetch base branch $BASE_BRANCH. Using changed files list only."
            DIFF_CONTENT="(Base branch not available for diff. Please refer to the changed files list above.)"
            # Write error-case diff directly into the repository workspace folder
            echo "$DIFF_CONTENT" > "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
          fi
          
        env:
          BASE_BRANCH: ${{ env.BASE_BRANCH }}

      - name: Generate Incremental Diff
        if: steps.review_type.outputs.is_first_review == 'false' && steps.review_type.outputs.last_reviewed_sha != ''
        id: incremental_diff
        run: |
          LAST_SHA=${{ steps.review_type.outputs.last_reviewed_sha }}
          CURRENT_SHA="${PR_HEAD_SHA}"
          DIFF_CONTENT=""
          # Ensure dedicated diff folder exists in the workspace (hidden to avoid accidental use)
          mkdir -p "$GITHUB_WORKSPACE/.mirrobot_files"
          echo "Attempting to generate incremental diff from $LAST_SHA to $CURRENT_SHA"
          
          # Fetch the last reviewed commit, handle potential errors (e.g., rebased/force-pushed commit)
          # First try fetching from origin
          if git fetch origin $LAST_SHA 2>/dev/null || git cat-file -e $LAST_SHA^{commit} 2>/dev/null; then
            echo "Successfully located $LAST_SHA."
            # Generate diff, fallback to empty if git diff fails (e.g., no common ancestor)
            if DIFF_CONTENT=$(git diff --patch $LAST_SHA..$CURRENT_SHA 2>/dev/null); then
              DIFF_SIZE=${#DIFF_CONTENT}
              DIFF_LINES=$(echo "$DIFF_CONTENT" | wc -l)
              echo "Generated incremental diff: $DIFF_LINES lines, $DIFF_SIZE characters"
              
              # Truncate if too large (500KB limit)
              if [ $DIFF_SIZE -gt 500000 ]; then
                echo "::warning::Incremental diff is very large ($DIFF_SIZE chars). Truncating to 500KB."
                TRUNCATION_MSG=$'\n\n[DIFF TRUNCATED - Changes are very large. Showing first 500KB only.]'
                DIFF_CONTENT="${DIFF_CONTENT:0:500000}${TRUNCATION_MSG}"
              fi
              # Write incremental diff directly into the repository workspace folder
              echo "$DIFF_CONTENT" > "$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt"
            else
              echo "::warning::Could not generate diff between $LAST_SHA and $CURRENT_SHA. Possible rebase/force-push. AI will perform full review."
              # Ensure an empty incremental diff file exists in the workspace folder as fallback
              echo "" > "$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt"
            fi
          else
            echo "::warning::Failed to fetch last reviewed SHA: $LAST_SHA. This can happen if the commit was part of a force-push or rebase. The AI will perform a full review as a fallback."
            # Ensure an empty incremental diff file exists in the workspace folder when last-SHA fetch fails
            echo "" > "$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt"
          fi
          
          # Ensure workspace diff files exist even on edge cases (in the hidden folder)
          [ -f "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt" ] || touch "$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
          [ -f "$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt" ] || touch "$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt"


      - name: Assemble Review Prompt
        env:
          REVIEW_TYPE: ${{ steps.review_type.outputs.is_first_review == 'true' && 'FIRST' || 'FOLLOW-UP' }}
          PR_AUTHOR: ${{ env.PR_AUTHOR }}
          IS_FIRST_REVIEW: ${{ steps.review_type.outputs.is_first_review }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_HEAD_SHA: ${{ env.PR_HEAD_SHA }}
          PULL_REQUEST_CONTEXT: ${{ env.PULL_REQUEST_CONTEXT }}
        run: |
          # Build DIFF_FILE_PATH pointing to the generated diff in the repository workspace
          if [ "${{ steps.review_type.outputs.is_first_review }}" = "true" ]; then
            DIFF_FILE_PATH="$GITHUB_WORKSPACE/.mirrobot_files/first_review_diff.txt"
          else
            DIFF_FILE_PATH="$GITHUB_WORKSPACE/.mirrobot_files/incremental_diff.txt"
          fi
          # Substitute variables, embedding PR context and diff file path; DIFF_FILE_PATH kept local to this process
          TMP_DIR="${RUNNER_TEMP:-/tmp}"
          VARS='${REVIEW_TYPE} ${PR_AUTHOR} ${IS_FIRST_REVIEW} ${PR_NUMBER} ${GITHUB_REPOSITORY} ${PR_HEAD_SHA} ${PULL_REQUEST_CONTEXT} ${DIFF_FILE_PATH}'
          DIFF_FILE_PATH="$DIFF_FILE_PATH" envsubst "$VARS" < /tmp/pr-review.md > "$TMP_DIR/assembled_prompt.txt"
          # Immediately clear large env after use
          echo "PULL_REQUEST_CONTEXT=" >> "$GITHUB_ENV"
          # Clear small, now-redundant flags included in the context summary
          echo "EXCLUDED_REVIEWS=" >> "$GITHUB_ENV" || true
          echo "EXCLUDED_COMMENTS=" >> "$GITHUB_ENV" || true
          echo "FILTER_ERROR_REVIEWS=" >> "$GITHUB_ENV" || true
          echo "FILTER_ERROR_COMMENTS=" >> "$GITHUB_ENV" || true

      - name: Review PR with OpenCode
        env:
          GITHUB_TOKEN: ${{ steps.setup.outputs.token }}
          OPENCODE_PERMISSION: |
            {
              "bash": {
                "gh*": "allow",
                "git*": "allow",
                "jq*": "allow"
              },
              "external_directory": "allow",
              "webfetch": "deny"
            }
          REVIEW_TYPE: ${{ steps.review_type.outputs.is_first_review == 'true' && 'FIRST' || 'FOLLOW-UP' }}
          PR_AUTHOR: ${{ env.PR_AUTHOR }}
          IS_FIRST_REVIEW: ${{ steps.review_type.outputs.is_first_review }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_HEAD_SHA: ${{ env.PR_HEAD_SHA }}
        run: |
          TMP_DIR="${RUNNER_TEMP:-/tmp}"
          opencode run --share - < "$TMP_DIR/assembled_prompt.txt"
